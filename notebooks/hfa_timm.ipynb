{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7461ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm # We import timm directly\n",
    "import numpy as np\n",
    "\n",
    "# --- Helper Module 1: High-Frequency Extractor ---\n",
    "class HighFrequencyExtractor(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(HighFrequencyExtractor, self).__init__()\n",
    "        # (Using 3 input channels for RGB)\n",
    "        sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32)\n",
    "        sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=np.float32)\n",
    "        sobel_weights_xy = np.stack([sobel_x, sobel_y], axis=0) # (2, 3, 3)\n",
    "        \n",
    "        final_weights = np.zeros((2 * in_channels, in_channels, 3, 3), dtype=np.float32)\n",
    "        for i in range(in_channels):\n",
    "            final_weights[i*2 : (i+1)*2, i, :, :] = sobel_weights_xy\n",
    "            \n",
    "        self.conv = nn.Conv2d(in_channels, 2 * in_channels, kernel_size=3, padding=1, groups=in_channels, bias=False)\n",
    "        self.conv.weight = nn.Parameter(torch.from_numpy(final_weights), requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "# --- Helper Module 2: Standard Convolution Block ---\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels), nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "# --- Helper Module 3: Standard Decoder Block ---\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, skip_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels // 2 + skip_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_up, x_skip):\n",
    "        x_up = self.up(x_up)\n",
    "        # Pad to handle potential size mismatch\n",
    "        diffY = x_skip.size()[2] - x_up.size()[2]\n",
    "        diffX = x_skip.size()[3] - x_up.size()[3]\n",
    "        x_up = F.pad(x_up, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x_skip, x_up], dim=1)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbe9b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HFANet_timm(nn.Module):\n",
    "    def __init__(self, encoder_name='resnet34', classes=1, pretrained=True, in_channels=3):\n",
    "        super(HFANet_timm, self).__init__()\n",
    "        \n",
    "        # --- 1. Spatial Stream (Backbone) ---\n",
    "        # Use timm to get just the backbone\n",
    "        self.backbone = timm.create_model(\n",
    "            encoder_name,\n",
    "            pretrained=pretrained,\n",
    "            features_only=True,\n",
    "            in_chans=in_channels\n",
    "        )\n",
    "        \n",
    "        # Get the channel counts from the backbone\n",
    "        # For resnet34, this is [64, 64, 128, 256, 512]\n",
    "        sp_channels = self.backbone.feature_info.channels()\n",
    "\n",
    "        # --- 2. High-Frequency Stream ---\n",
    "        self.hf_extractor = HighFrequencyExtractor(in_channels=in_channels)\n",
    "        hf_channels = in_channels * 2 # 3*2 = 6\n",
    "\n",
    "        # --- 3. HFA Module (to process the skip connections) ---\n",
    "        # This module will process the HF diff and the *first* spatial diff map\n",
    "        # sp_channels[0] is the stem (64 channels, 1/2 res)\n",
    "        # sp_channels[1] is layer1 (64 channels, 1/4 res)\n",
    "        \n",
    "        # Let's apply HFA to the features from stage 1 (1/4 res)\n",
    "        self.hf_attention_head = nn.Sequential(\n",
    "            nn.Conv2d(hf_channels, 16, kernel_size=3, stride=2, padding=1, bias=False), # 1/2 res\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 1, kernel_size=3, stride=2, padding=1, bias=False), # 1/4 res\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Fusion conv for the HFA-applied features\n",
    "        # It takes (raw spatial diff) + (attended spatial diff)\n",
    "        self.fusion_s1 = nn.Sequential(\n",
    "            nn.Conv2d(sp_channels[1] * 2, sp_channels[1], kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(sp_channels[1]),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # --- 4. Manual Decoder ---\n",
    "        # We now have to build the decoder by hand\n",
    "        self.dec_layer4 = DecoderBlock(sp_channels[4], sp_channels[3], 256)\n",
    "        self.dec_layer3 = DecoderBlock(256, sp_channels[2], 128)\n",
    "        self.dec_layer2 = DecoderBlock(128, sp_channels[1], 64) # HFA will be applied to skip[1]\n",
    "        self.dec_layer1 = DecoderBlock(64, sp_channels[0], 64)\n",
    "        \n",
    "        self.final_up = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.final_conv = nn.Conv2d(32, classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \n",
    "        # --- 1. High-Frequency Stream ---\n",
    "        hf_t1 = self.hf_extractor(x1) # (B, 6, 256, 256)\n",
    "        hf_t2 = self.hf_extractor(x2) # (B, 6, 256, 256)\n",
    "        hf_diff = torch.abs(hf_t1 - hf_t2)\n",
    "\n",
    "        # --- 2. Spatial Stream (Siamese) ---\n",
    "        # Returns a list of 5 feature maps (stem, layer1, layer2, layer3, layer4)\n",
    "        sp_features_t1 = self.backbone(x1)\n",
    "        sp_features_t2 = self.backbone(x2)\n",
    "        \n",
    "        # Get the differences for all skip connections\n",
    "        d0 = torch.abs(sp_features_t1[0] - sp_features_t2[0])\n",
    "        d1 = torch.abs(sp_features_t1[1] - sp_features_t2[1])\n",
    "        d2 = torch.abs(sp_features_t1[2] - sp_features_t2[2])\n",
    "        d3 = torch.abs(sp_features_t1[3] - sp_features_t2[3])\n",
    "        d4 = torch.abs(sp_features_t1[4] - sp_features_t2[4]) # Bottleneck\n",
    "\n",
    "        # --- 3. Apply HFA Module ---\n",
    "        # Create mask from HF features (at 1/4 res)\n",
    "        hf_attention_mask = self.hf_attention_head(hf_diff)\n",
    "        \n",
    "        # Apply attention to the corresponding spatial difference map (d1)\n",
    "        attended_d1 = d1 * hf_attention_mask\n",
    "        \n",
    "        # Fuse the attended and original features\n",
    "        fused_d1 = self.fusion_s1(torch.cat([d1, attended_d1], dim=1))\n",
    "        \n",
    "        # --- 4. Manual Decoder Path ---\n",
    "        # We pass the fused_d1 as the skip connection\n",
    "        dec4 = self.dec_layer4(d4, d3)\n",
    "        dec3 = self.dec_layer3(dec4, d2)\n",
    "        dec2 = self.dec_layer2(dec3, fused_d1) # <- HFA is applied here\n",
    "        dec1 = self.dec_layer1(dec2, d0)\n",
    "        \n",
    "        out = self.final_up(dec1)\n",
    "        out = self.final_conv(out)\n",
    "        \n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
