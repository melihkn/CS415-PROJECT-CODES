{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa8c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/segnet.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "class ConvBNReLU(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k=3, p=1):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=k, padding=p, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class SegNetDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Lightweight SegNet-ish decoder:\n",
    "    - Takes multi-scale encoder features (from SMP encoder)\n",
    "    - Uses abs(fA - fB) at each scale (siamese)\n",
    "    - Progressive upsampling + skip fusion\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder_channels, decoder_channels=(256, 128, 64, 32, 16)):\n",
    "        \"\"\"\n",
    "        encoder_channels: list of channels from SMP encoder .out_channels\n",
    "            Usually length = 6 for ResNet encoders: [in, c1, c2, c3, c4, c5]\n",
    "            Features list returned by encoder has same length.\n",
    "        decoder_channels: 5 stages (from deepest to shallowest fusion)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert len(decoder_channels) == 5, \"decoder_channels must have 5 elements\"\n",
    "\n",
    "        # SMP encoder gives features: [f0, f1, f2, f3, f4, f5] (f5 deepest)\n",
    "        # We'll decode from f5 -> f1, then output at f0 resolution.\n",
    "        ch = encoder_channels\n",
    "        d = decoder_channels\n",
    "\n",
    "        # stage 5: up f5 and fuse with f4\n",
    "        self.up5 = ConvBNReLU(ch[5], d[0])\n",
    "        self.fuse5 = ConvBNReLU(d[0] + ch[4], d[0])\n",
    "\n",
    "        # stage 4: up and fuse with f3\n",
    "        self.up4 = ConvBNReLU(d[0], d[1])\n",
    "        self.fuse4 = ConvBNReLU(d[1] + ch[3], d[1])\n",
    "\n",
    "        # stage 3: up and fuse with f2\n",
    "        self.up3 = ConvBNReLU(d[1], d[2])\n",
    "        self.fuse3 = ConvBNReLU(d[2] + ch[2], d[2])\n",
    "\n",
    "        # stage 2: up and fuse with f1\n",
    "        self.up2 = ConvBNReLU(d[2], d[3])\n",
    "        self.fuse2 = ConvBNReLU(d[3] + ch[1], d[3])\n",
    "\n",
    "        # stage 1: up to f0 scale (input scale) and refine\n",
    "        self.up1 = ConvBNReLU(d[3], d[4])\n",
    "        self.refine = nn.Sequential(\n",
    "            ConvBNReLU(d[4], d[4]),\n",
    "            ConvBNReLU(d[4], d[4]),\n",
    "        )\n",
    "\n",
    "    def forward(self, diffs):\n",
    "        \"\"\"\n",
    "        diffs: list [df0, df1, df2, df3, df4, df5] where dfi = abs(fAi - fBi)\n",
    "        \"\"\"\n",
    "        df0, df1, df2, df3, df4, df5 = diffs\n",
    "\n",
    "        # Start from deepest df5\n",
    "        x = self.up5(df5)\n",
    "        x = F.interpolate(x, size=df4.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        x = self.fuse5(torch.cat([x, df4], dim=1))\n",
    "\n",
    "        x = self.up4(x)\n",
    "        x = F.interpolate(x, size=df3.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        x = self.fuse4(torch.cat([x, df3], dim=1))\n",
    "\n",
    "        x = self.up3(x)\n",
    "        x = F.interpolate(x, size=df2.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        x = self.fuse3(torch.cat([x, df2], dim=1))\n",
    "\n",
    "        x = self.up2(x)\n",
    "        x = F.interpolate(x, size=df1.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        x = self.fuse2(torch.cat([x, df1], dim=1))\n",
    "\n",
    "        x = self.up1(x)\n",
    "        x = F.interpolate(x, size=df0.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        x = self.refine(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SegNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Siamese (shared encoder) SegNet-style change detector.\n",
    "    Pretrained encoder is loaded via SMP encoder weights (\"imagenet\").\n",
    "    Output: logits [B, 1, H, W]\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone_name: str = \"resnet34\",\n",
    "        pretrained: bool = True,\n",
    "        in_channels: int = 3,\n",
    "        decoder_channels=(256, 128, 64, 32, 16),\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        weights = \"imagenet\" if pretrained else None\n",
    "        self.encoder = smp.encoders.get_encoder(\n",
    "            name=backbone_name,\n",
    "            in_channels=in_channels,\n",
    "            depth=5,\n",
    "            weights=weights,\n",
    "        )\n",
    "\n",
    "        self.decoder = SegNetDecoder(\n",
    "            encoder_channels=self.encoder.out_channels,\n",
    "            decoder_channels=decoder_channels,\n",
    "        )\n",
    "\n",
    "        self.seg_head = nn.Conv2d(decoder_channels[-1], 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # encoder returns list of features: [f0..f5]\n",
    "        f1 = self.encoder(x1)\n",
    "        f2 = self.encoder(x2)\n",
    "\n",
    "        # Siamese difference at each scale\n",
    "        diffs = [torch.abs(a - b) for a, b in zip(f1, f2)]\n",
    "\n",
    "        x = self.decoder(diffs)\n",
    "        logits = self.seg_head(x)\n",
    "        return logits\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
